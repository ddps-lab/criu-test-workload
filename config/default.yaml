# CRIU Workload Experiment Configuration
# =========================================
# Default configuration for CRIU checkpoint/migration experiments
#
# Node configuration is loaded from servers.yaml (auto-generated by Terraform).
# If servers.yaml doesn't exist, environment variables are used as fallback.

# Experiment metadata
experiment:
  name: "default-experiment"
  workload_type: "memory"
  description: "Default CRIU checkpoint experiment"
  save_metrics: true
  metrics_file: "metrics.json"

# Node configuration (fallback if servers.yaml doesn't exist)
# In AWS Lab, servers.yaml is auto-generated by Terraform with actual IPs.
# For manual setup, set SOURCE_NODE_IP and DEST_NODE_IP environment variables.
nodes:
  ssh_user: "ubuntu"
  ssh_key: "~/.ssh/id_ed25519"

  # Source node (where workload runs and checkpoint is taken)
  source:
    ip: "${SOURCE_NODE_IP}"
    name: "source-node"

  # Destination node (where workload is restored)
  destination:
    ip: "${DEST_NODE_IP}"
    name: "dest-node"

# Checkpoint strategy configuration
checkpoint:
  # Directories
  dirs:
    working_dir: "/tmp/criu_checkpoint"

  # Strategy: 'predump' or 'full'
  strategy:
    mode: "predump"

    # Pre-dump configuration (only for mode: predump)
    predump_iterations: 8
    predump_interval: 10  # seconds between iterations
    sync_after_predump: false  # sync to EBS/EFS after each pre-dump

    # Lazy mode configuration
    # Available modes:
    #   - none: Standard restore, all pages must be present locally
    #   - lazy: Lazy-pages from local directory
    #   - lazy-prefetch: Lazy with S3 async prefetch (requires S3)
    #   - live-migration: Page-server based live migration (post-copy)
    #   - live-migration-prefetch: S3 pre-copy + page-server post-copy (requires S3)
    lazy_mode: "none"
    page_server_port: 27
    prefetch_workers: 4

    # Full dump configuration (only for mode: full)
    wait_before_dump: 30  # seconds to wait before dump

# Transfer configuration
transfer:
  # Method: 'rsync', 's3', 'efs', 'ebs'
  method: "rsync"

  # Destination directory for rsync
  dest_dir: "/tmp/criu_checkpoint"

  # S3 configuration (for method: s3)
  # s3_bucket: "${AWS_S3_BUCKET}"
  # s3_prefix: "checkpoints"

  # EFS configuration (for method: efs)
  # efs_mount: "/mnt/efs"

  # EBS configuration (for method: ebs)
  # ebs_mount: "/mnt/ebs_test"

# S3 Object Storage configuration (for CRIU lazy restore from S3)
# Used when transfer.method is 's3' and lazy_mode is 'lazy-prefetch' or 'live-migration-prefetch'
s3:
  # S3 type: standard, cloudfront, express-one-zone
  type: "standard"

  # Upload settings (source node -> S3)
  upload_bucket: ""  # Required: S3 bucket name
  prefix: ""         # Optional: Object prefix (e.g., "checkpoints/exp1")
  region: ""         # AWS region (e.g., "ap-northeast-2")

  # Download settings (for CRIU object storage)
  # download_endpoint varies by type:
  #   - standard: s3.{region}.amazonaws.com
  #   - cloudfront: {distribution}.cloudfront.net
  #   - express-one-zone: s3express-{az}.{region}.amazonaws.com
  download_endpoint: ""
  download_bucket: ""  # Default: same as upload_bucket

  # Express One Zone specific (credentials required)
  # Recommended: use environment variables instead of hardcoding
  access_key: "${AWS_ACCESS_KEY_ID}"
  secret_key: "${AWS_SECRET_ACCESS_KEY}"
  # Note: Async prefetch settings are now in checkpoint.strategy section (prefetch_workers)

# Workload configuration
workload:
  # Common settings
  working_dir: "/tmp/criu_checkpoint"

  # Readiness check
  readiness:
    file_path: "checkpoint_ready"
    timeout: 300  # seconds to wait for workload to be ready

# Paths configuration
# These paths are on the WORKLOAD nodes (not control node)
paths:
  # Where workload scripts are deployed on workload nodes
  scripts_dir: "/tmp/criu_checkpoint"

  # Where workload data files are stored (for workloads that need input data)
  data_dir: "/tmp/criu_data"

  # Data setup options
  data_setup:
    # How to prepare data: 'generate', 'download', 'none'
    method: "generate"

    # For method: download
    # s3_bucket: "my-bucket"
    # s3_prefix: "workload-data"

    # For method: generate
    # Data is generated by the workload itself (e.g., testsrc for ffmpeg)

# Migration success criteria
migration:
  # What to measure
  metrics:
    - checkpoint_time      # Time to dump process
    - transfer_time        # Time to transfer checkpoint images
    - restore_time         # Time to restore process
    - total_downtime       # checkpoint_time + transfer_time + restore_time
    - data_integrity       # Verify data after restore (for redis, etc.)

  # Success conditions
  success_criteria:
    # Process must be running after restore
    process_running: true
    # Data integrity check must pass (for applicable workloads)
    data_integrity_check: true

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
